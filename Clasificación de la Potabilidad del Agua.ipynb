{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd179a21-995e-42d7-8162-c0c6a48cf289",
   "metadata": {},
   "source": [
    "# **Clasificación de la Potabilidad del Agua** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809e58b-2920-4b64-911e-cf38f8776aaa",
   "metadata": {},
   "source": [
    "## 1. Definición del Caso de Uso\n",
    "\n",
    "La disponibilidad de agua potable es un pilar fundamental para la salud pública y el desarrollo sostenible a nivel mundial. La calidad del agua puede variar drásticamente debido a factores naturales, actividad industrial y prácticas agrícolas, lo que hace que su monitoreo y clasificación sean tareas críticas.\n",
    "\n",
    "El objetivo de este proyecto es construir un modelo de Machine Learning capaz de clasificar si una muestra de agua es potable o no, basándose en un conjunto de sus propiedades. Esto no solo ayuda a identificar fuentes de agua seguras, sino que también puede ser una herramienta valiosa para la detección temprana de problemas de contaminación y la optimización de los procesos de tratamiento de agua.\n",
    "\n",
    "Este problema es de gran relevancia en el mundo real. La ingesta de agua no potable es una causa principal de enfermedades transmitidas por el agua, afectando especialmente a poblaciones vulnerables. Un sistema de clasificación automatizado puede complementar los costosos y lentos análisis de laboratorio, permitiendo una evaluación más rápida y frecuente de la calidad del agua en diversas ubicaciones.\n",
    "\n",
    "Existen numerosos estudios y aplicaciones en este campo. Por ejemplo, la optimización del tratamiento de aguas residuales mediante ML, la predicción de la calidad del agua en ríos y lagos, y el desarrollo de sistemas de alerta temprana para eventos de contaminación son áreas activas de investigación. Este proyecto busca ser una base para comprender cómo el Machine Learning puede aplicarse para abordar estos desafíos cruciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472cebb-d4a0-4c38-a861-b9ae031cec5c",
   "metadata": {},
   "source": [
    "## 2. Análisis del Dataset\n",
    "\n",
    "### Origen y Descripción\n",
    "\n",
    "El dataset principal para este proyecto es el conjunto de datos **\"Water Quality\"** de Kaggle. Este dataset contiene varias características fisicoquímicas del agua y una variable objetivo que indica si el agua es potable.\n",
    "\n",
    "### Tamaño del Dataset\n",
    "\n",
    "Este dataset consta de 3276 filas (muestras de agua) y 10 columnas (9 características predictoras + 1 variable objetivo).\n",
    "\n",
    "### Descripción de las Características y la Variable Objetivo\n",
    "\n",
    "Las características incluidas en el dataset son:\n",
    "\n",
    "- **`ph`**: pH del agua (escala de 0 a 14).\n",
    "- **`Hardness`**: Dureza del agua, una medida de la concentración de minerales disueltos (mg/L).\n",
    "- **`Solids`**: Sólidos totales disueltos (ppm).\n",
    "- **`Chloramines`**: Cloraminas en el agua (ppm).\n",
    "- **`Sulfate`**: Sulfatos en el agua (mg/L).\n",
    "- **`Conductivity`**: Conductividad eléctrica del agua (microS/cm).\n",
    "- **`Organic_carbon`**: Carbono orgánico total en el agua (ppm).\n",
    "- **`Trihalomethanes`**: Trihalometanos en el agua (microg/L).\n",
    "- **`Turbidity`**: Turbidez del agua (NTU).\n",
    "- **`Potability`**: Variable objetivo. Indica si el agua es potable (1) o no potable (0).\n",
    "\n",
    "### Preprocesado y Linaje\n",
    "\n",
    "Según la documentación de Kaggle, este dataset ya está relativamente limpio, pero una inspección inicial revelará si existen valores nulos o si se requieren transformaciones adicionales. Para este proyecto, asumimos que no hay un preprocesamiento complejo ya aplicado que altere significativamente la naturaleza de los datos crudos.\n",
    "\n",
    "### Licencia\n",
    "\n",
    "Asumimos una licencia de uso libre o pública, común en datasets disponibles en plataformas como OpenML y Kaggle, que permite su uso para fines educativos y de investigación.\n",
    "\n",
    "### Idoneidad del Tamaño y Número de Características\n",
    "\n",
    "Con 3276 filas y 9 características, el dataset es de un tamaño adecuado para un proyecto de clasificación para juniors. No es excesivamente grande, lo que permite un entrenamiento rápido en entornos estándar (como Google Colab o una máquina local con CPU y 4-8GB RAM), y las 9 características son suficientes para explorar relaciones sin caer en la maldición de la dimensionalidad para modelos simples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14bdc7-f0b1-497b-a18e-f8d1e54607f9",
   "metadata": {},
   "source": [
    "## 3. Definición de Requisitos Técnicos\n",
    "\n",
    "Para este proyecto de clasificación, definiremos una serie de requisitos técnicos que guiarán nuestro desarrollo y evaluación del modelo.\n",
    "\n",
    "### Métricas de Evaluación Propuestas\n",
    "\n",
    "Dado que el problema es la clasificación de la potabilidad del agua, es crucial ser muy preciso en nuestras métricas, especialmente si hay un desequilibrio de clases. Las métricas que utilizaremos son:\n",
    "\n",
    "- **Accuracy (Exactitud)**: La proporción de predicciones correctas sobre el total de predicciones. Es una métrica general, útil para tener una visión rápida del rendimiento.\n",
    "- **Precision (Precisión)**: La proporción de verdaderos positivos sobre el total de elementos clasificados como positivos. En este contexto, nos indica cuántas de las muestras que el modelo clasificó como potables son realmente potables. Evita falsos positivos excesivos (clasificar agua no potable como potable).\n",
    "- **Recall (Sensibilidad/Exhaustividad)**: La proporción de verdaderos positivos sobre el total de elementos que realmente son positivos. Para la potabilidad del agua, nos indica cuántas de las muestras realmente potables fueron identificadas correctamente. Es crucial para minimizar **falsos negativos** (clasificar agua potable como no potable, lo cual no es tan grave como lo contrario, pero puede generar alarmas innecesarias o desaprovechamiento). Sin embargo, en un escenario real, el falso negativo (clasificar agua no potable como potable) sería la métrica más crítica a minimizar, lo que requeriría un alto Recall para la clase \"no potable\" o una alta Precision para la clase \"potable\" si asumimos que es más peligroso beber agua no potable. Dada la naturaleza de este problema, un alto **Recall para la clase \"potable\"** significa que el modelo es bueno identificando toda el agua potable, y un alto **Precision para la clase \"no potable\"** significa que cuando el modelo dice que el agua no es potable, es muy probable que sea cierto. Para simplificar para principiantes, nos enfocaremos en un equilibrio general, pero la interpretación de estas métricas es clave.\n",
    "- **F1-Score**: La media armónica de la precisión y el recall. Es útil cuando hay un desequilibrio de clases, ya que penaliza los modelos que tienen un buen rendimiento en una métrica pero no en la otra.\n",
    "- **AUC-ROC (Área bajo la Curva ROC)**: Mide la capacidad de un clasificador para distinguir entre clases. Un valor más alto indica un mejor rendimiento. Es robusto ante el desequilibrio de clases.\n",
    "\n",
    "### Precisión del Modelo Aceptable y Deseable\n",
    "\n",
    "- **Precisión mínima aceptable**: >70−75%\n",
    "- **Precisión deseable**: >85%\n",
    "\n",
    "Estos umbrales nos darán una referencia clara del éxito del modelo.\n",
    "\n",
    "### Recursos\n",
    "\n",
    "Asumimos un entorno de ejecución estándar, como **Google Colab** o una máquina local con las siguientes especificaciones:\n",
    "\n",
    "- **CPU**: Procesador de propósito general.\n",
    "- **RAM**: 4-8 GB de memoria RAM.\n",
    "\n",
    "### Tiempo Máximo de Entrenamiento\n",
    "\n",
    "Para la iteración de modelos individuales, el tiempo de entrenamiento no debería exceder los **5 minutos por modelo**. Esto es crucial para mantener un ciclo de experimentación ágil y eficiente. Para optimización de hiperparámetros con técnicas como GridSearchCV, el tiempo podría ser un poco mayor, pero siempre buscando la eficiencia.\n",
    "\n",
    "### Documentación de Dependencias\n",
    "\n",
    "Las librerías principales que utilizaremos para este proyecto son:\n",
    "\n",
    "- `numpy` (manipulación numérica)\n",
    "- `pandas` (manipulación de datos, DataFrames)\n",
    "- `scikit-learn` (modelos de Machine Learning, preprocesamiento, métricas)\n",
    "- `matplotlib` (visualización de datos)\n",
    "- `seaborn` (visualización de datos mejorada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f13c31-60c6-48e6-8a38-bf53eb47a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy pandas scikit-learn matplotlib seaborn openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf93d53-b075-4a7d-8760-1c03f8e6f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imbalanced-lear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed116d-2056-4b04-af20-3274d31d422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dcfbfe-b8fe-4182-bbc8-6274c97c6030",
   "metadata": {},
   "source": [
    "## 4. Análisis de Datos Exploratorio (EDA) Detallado y Preprocesamiento\n",
    "\n",
    "En esta sección, realizaremos un análisis exhaustivo del dataset para comprender sus características, identificar problemas de calidad de datos y preparar los datos para el modelado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4791c-c945-4d5f-85d4-ca210ec2830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos importando las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import openml\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import warnings\n",
    "\n",
    "# Ignorar warnings para una salida más limpia en el notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración para visualizaciones\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564d434-65e3-4db1-88cf-238a263a79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_quality = pd.read_csv('water_potability.csv')\n",
    "print(\"Dataset 'water_potability.csv' cargado exitosamente.\")\n",
    "\n",
    "# Dimensiones del DataFrame\n",
    "print(\"\\nDimensiones del DataFrame:\")\n",
    "print(water_quality.shape)\n",
    "\n",
    "# Información general del DataFrame (tipos de datos, nulos, uso de memoria)\n",
    "print(\"\\nInformación general del DataFrame:\")\n",
    "water_quality.info()\n",
    "\n",
    "# Estadísticas descriptivas de las columnas numéricas\n",
    "print(\"\\nEstadísticas descriptivas del DataFrame:\")\n",
    "water_quality.describe().T\n",
    "\n",
    "# Primeras 5 filas del DataFrame\n",
    "print(\"\\nPrimeras 5 filas del DataFrame:\")\n",
    "print(water_quality.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afeaef-111c-4340-80be-67330e7467c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobación de Valores Nulos/Faltantes\n",
    "print(\"Conteo de valores nulos por columna:\")\n",
    "print(water_quality.isnull().sum())\n",
    "print(\"\\nPorcentaje de valores nulos por columna:\")\n",
    "print((water_quality.isnull().sum() / len(water_quality)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e840be1-09e6-4f57-9db4-6626bc5261f4",
   "metadata": {},
   "source": [
    "**Discusión sobre la estrategia para manejar los nulos:**\n",
    "\n",
    "Observamos que las columnas 'ph', 'Sulfate' y 'Trihalomethanes' contienen valores nulos. Para un proyecto de clasificación para principiantes y dado el tamaño del dataset, una estrategia robusta y sencilla es la **imputación con la mediana**. La mediana es menos sensible a los outliers que la media, lo que la hace una opción más segura para rellenar valores faltantes en distribuciones que puedan ser asimétricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f1b82-df30-4316-99f5-810fe5329c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de valores nulos con la mediana\n",
    "numerical_cols = water_quality.drop('Potability', axis=1).columns\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Aplicar el imputer a las columnas numéricas que tienen nulos\n",
    "# Fit y transform para las columnas originales\n",
    "water_quality[numerical_cols] = imputer.fit_transform(water_quality[numerical_cols]) # Excluir la variable objetivo\n",
    "\n",
    "print(\"\\nConteo de valores nulos después de la imputación:\")\n",
    "print(water_quality.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573adfd-71e7-40eb-8413-8f1e9c6d5e93",
   "metadata": {},
   "source": [
    "### Análisis y Visualización de Outliers\r\n",
    "\r\n",
    "Los outliers pueden distorsionar los resultados del modelo. Visualizaremos las distribuciones de las características clave usando boxplots para identificar posibles outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a02da6-e910-445a-b89c-029e32c25d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(y=water_quality[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60aee94-615d-41b4-ade3-f0068a6361c0",
   "metadata": {},
   "source": [
    "**Discusión sobre el manejo de outliers:**\n",
    "\n",
    "Podemos observar la presencia de outliers en varias características (ej., `Solids`, `Chloramines`, `Sulfate`, `Trihalomethanes`). Para este proyecto introductorio, **decidimos mantener los outliers**. La razón es doble:\n",
    "\n",
    "1. **Simplicidad para principiantes**: La eliminación o transformación de outliers puede añadir una capa de complejidad al preprocesamiento que no es el foco principal para una introducción.\n",
    "2. **Robustez de los modelos**: Algunos modelos (como Random Forest) son inherentemente más robustos a los outliers que otros (como Regresión Logística, SVM lineal). Mantenerlos nos permitirá ver cómo los diferentes modelos manejan esta característica de los datos. En un proyecto más avanzado, se considerarían técnicas como la winsorización o transformaciones logarítmicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc0fcd4-3649-4b0d-92fb-c7184e3b5d0a",
   "metadata": {},
   "source": [
    "### Análisis de Características\n",
    "\n",
    "Exploraremos las distribuciones de las características numéricas y su relación con la variable objetivo\n",
    "\n",
    "**Numéricas: Histogramas y KDE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49966854-0eab-43b8-af85-4c9c5a089d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.histplot(water_quality[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribución de {col}')\n",
    "    plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f6b6e-6c6b-44a8-8e3d-36ecd008dcae",
   "metadata": {},
   "source": [
    "**Relación con la variable objetivo (scatter plots o boxplots condicionales):**\r\n",
    "\r\n",
    "Para ver la relación entre las características y la potabilidad, usaremos boxplots condicionales, ya que la variable objetivo es binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4535263-41aa-4b87-890c-b3a0ae5704b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x='Potability', y=col, data=water_quality)\n",
    "    plt.title(f'{col} vs. Potability')\n",
    "    plt.xlabel('Potability (0: No, 1: Sí)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df1a06-3fc3-4177-a49c-2143f8705317",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "- Algunas características como `ph`, `Sulfate`, y `Trihalomethanes` muestran distribuciones más o menos simétricas o ligeramente sesgadas.\n",
    "- `Solids` presenta una cola larga a la derecha, indicando un sesgo positivo y la presencia de valores muy altos (outliers).\n",
    "- Los boxplots condicionales muestran que para algunas características, las medianas o las distribuciones entre las clases `Potability` 0 y 1 son ligeramente diferentes, lo que sugiere que estas características podrían ser predictivas. Por ejemplo, el `ph` parece tener una distribución ligeramente diferente entre las dos categorías, al igual que `Solids` y `Sulfate`.\n",
    "\n",
    "### Categóricas (N/A)\n",
    "\n",
    "En este dataset, todas las características predictoras son numéricas. Por lo tanto, no se requiere codificación de variables categóricas.\n",
    "\n",
    "### Variable Objetivo: Distribución de 'Potability'\n",
    "\n",
    "Es crucial verificar el equilibrio de la variable objetivo. Un desequilibrio de clases puede afectar significativamente el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c2630-1fba-47c5-8b87-19fae0debfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.countplot(x='Potability', data=water_quality)\n",
    "plt.title('Distribución de la Potabilidad del Agua')\n",
    "plt.xlabel('Potability (0: No potable, 1: Potable)')\n",
    "plt.ylabel('Conteo')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda5eab-819b-4448-86f2-b90eee9f5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConteo de clases de la variable objetivo:\")\n",
    "print(water_quality['Potability'].value_counts())\n",
    "print(\"\\nPorcentaje de clases de la variable objetivo:\")\n",
    "print(water_quality['Potability'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30254cfd-37ad-43b3-8b74-c969a6d1f624",
   "metadata": {},
   "source": [
    "**Observación clave:**\r\n",
    "\r\n",
    "Existe un **desequilibrio de clases significativo**. La clase \"No potable\" (0) es mayoritaria (alrededor del 60%) en comparación con la clase \"Potable\" (1) (alrededor del 40%). Esto significa que los modelos podrían tender a predecir la clase mayoritaria. Tendremos esto en cuenta al evaluar las métricas, especialmente Precision, Recall y F1-Score, ya que la Accuracy por sí sola podría ser engañosa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e24c8f-be9b-4bf8-9f3c-975c6f606207",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "### Escalado/Normalización de características numéricas\n",
    "\n",
    "El escalado de características es un paso crucial para muchos algoritmos de Machine Learning (como Regresión Logística, SVM) que son sensibles a la escala de los datos. `StandardScaler` es una buena opción, ya que estandariza las características eliminando la media y escalando a la varianza unitaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a06e1-7bc6-48e9-a477-ccd99338e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características (X) y variable objetivo (y)\n",
    "X = water_quality.drop('Potability', axis=1)\n",
    "y = water_quality['Potability']\n",
    "\n",
    "# Inicializar el StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicar el escalado a las características\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir de nuevo a DataFrame para facilitar la inspección \n",
    "X_scaled_wq = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nPrimeras 5 filas de las características escaladas:\")\n",
    "print(X_scaled_wq.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa8a5e-1c43-42d2-8bbc-43b46abe5b18",
   "metadata": {},
   "source": [
    "### Correlación\n",
    "\n",
    "Analizar la matriz de correlación nos permite entender las relaciones lineales entre las características y con la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47abf61-cb35-4348-9f68-9dde3a7e1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(water_quality.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Matriz de Correlación de las Características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45cf6a-af7d-417f-86b0-6165c857c7b9",
   "metadata": {},
   "source": [
    "**Observaciones de la matriz de correlación:**\n",
    "\n",
    "- Las correlaciones entre las características no son extremadamente altas, lo que es bueno, ya que indica que no hay una multicolinealidad severa que pueda afectar negativamente a algunos modelos lineales.\n",
    "- La correlación de las características con la variable `Potability` es generalmente baja. Esto sugiere que la relación entre las características y la potabilidad puede ser no lineal o que cada característica por sí sola tiene un poder predictivo limitado, y el modelo deberá aprender interacciones complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c21917-7019-46b2-bbe2-573486b0a758",
   "metadata": {},
   "source": [
    "### División del Dataset\n",
    "\n",
    "Dividiremos el dataset en conjuntos de entrenamiento y prueba. Usaremos K-Fold Cross Validation durante el entrenamiento para una evaluación más robusta del modelo, y reservaremos un conjunto de prueba final para la evaluación definitiva del mejor modelo. Para este proyecto, usaremos una división 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a959af1-6ece-401b-9dfa-da2cdeb8da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos stratify por el desequilibrio de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y) \n",
    "\n",
    "print(f\"Dimensiones del conjunto de entrenamiento X: {X_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba X: {X_test.shape}\")\n",
    "print(f\"Dimensiones del conjunto de entrenamiento y: {y_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba y: {y_test.shape}\")\n",
    "\n",
    "# Verificación de la distribución de clases en los conjuntos divididos\n",
    "print(\"\\nDistribución de clases en y_train:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(\"\\nDistribución de clases en y_test:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7d57d-b4ce-46db-a6ad-dd7d65a7c985",
   "metadata": {},
   "source": [
    "La estratificación asegura que la proporción de clases en los conjuntos de entrenamiento y prueba sea similar a la del dataset original, lo cual es crucial dado el desequilibrio de clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92f5b3-b5e9-452f-8210-5796814a9421",
   "metadata": {},
   "source": [
    "## 5. Funciones Auxiliares\n",
    "\n",
    "Para mantener nuestro código limpio y reutilizable, definiremos algunas funciones auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e2032-60a5-4d7f-9c29-3fba2c9574aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distributions(water_quality, columns, suptitle=\"Distribución de Características\"):\n",
    "    \"\"\"\n",
    "    Grafica histogramas y KDE para las columnas especificadas de un DataFrame.\n",
    "       Args:\n",
    "        water_quality (pd.DataFrame): DataFrame de entrada.\n",
    "        columns (list): Lista de nombres de columnas a graficar.\n",
    "        suptitle (str): Título general para el conjunto de gráficos.\n",
    "    \"\"\"\n",
    "    num_cols = len(columns)\n",
    "    num_rows = (num_cols + 2) // 3 # Calcular número de filas para 3 columnas por fila\n",
    "    plt.figure(figsize=(15, 5 * num_rows))\n",
    "    plt.suptitle(suptitle, fontsize=16, y=1.02) # Ajustar la posición del título\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        plt.subplot(num_rows, 3, i + 1)\n",
    "        sns.histplot(water_quality[col], kde=True, bins=30)\n",
    "        plt.title(f'Distribución de {col}')\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('Frecuencia')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98]) # Ajustar layout para el título\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Modelo\"):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de clasificación y muestra sus métricas clave.\n",
    "\n",
    "    Args:\n",
    "        model: El modelo de clasificación entrenado.\n",
    "        X_test (np.array o pd.DataFrame): Conjunto de características de prueba.\n",
    "        y_test (np.array o pd.Series): Etiquetas verdaderas de prueba.\n",
    "        model_name (str): Nombre del modelo para la salida.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else 'N/A'\n",
    "\n",
    "    print(f\"--- Evaluación del {model_name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Predicción: No Potable', 'Predicción: Potable'],\n",
    "                yticklabels=['Real: No Potable', 'Real: Potable'])\n",
    "    plt.title(f'Matriz de Confusión para {model_name}')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "\n",
    "    # Curva ROC\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (área = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Tasa de Falsos Positivos')\n",
    "        plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "        plt.title(f'Curva ROC para {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02ad61-7d67-4625-a6a9-26af3dd68723",
   "metadata": {},
   "source": [
    "## 6. Modelo Base\n",
    "\n",
    "Para nuestro modelo base, seleccionaremos la **Regresión Logística**.\n",
    "\n",
    "### Justificación de la Elección\n",
    "\n",
    "La Regresión Logística es un excelente punto de partida para problemas de clasificación binaria por varias razones:\n",
    "\n",
    "- **Simplicidad y Facilidad de Interpretación**: Es un algoritmo lineal que es fácil de entender y sus coeficientes pueden interpretarse.\n",
    "- **Eficiencia Computacional**: Se entrena rápidamente, lo que cumple con nuestro requisito de tiempo de entrenamiento.\n",
    "- **Buen Rendimiento para Datos Separables Linealmente**: Aunque la correlación con la potabilidad es baja, siempre es una buena primera prueba para ver si existe alguna separación lineal básica.\n",
    "\n",
    "### Entrenamiento del Modelo Base\n",
    "\n",
    "Entrenaremos el modelo utilizando los datos preprocesados (`X_train_scaled`, `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ddc38-e1ec-41ba-ba65-43919b606928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ha añadido class_weight='balanced' para manejar el desequilibrio de clases.\n",
    "# Anteriormente, el modelo predecía casi exclusivamente la clase mayoritaria (0),\n",
    "# resultando en Precision, Recall y F1-Score en 0.0000 para la clase minoritaria (1).\n",
    "log_reg_model = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced') # solver 'liblinear' es bueno para datasets pequeños\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo de Regresión Logística base entrenado con class_weight='balanced'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659b057-281c-418a-9d0e-6272362385d1",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo Base\n",
    "\n",
    "Ahora, evaluaremos el rendimiento de nuestro modelo base en el conjunto de prueba (`X_test`, `y_test`) utilizando las métricas definidas y la función auxiliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01586c03-4030-4f38-af01-f7bc89d452b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(log_reg_model, X_test, y_test, model_name=\"Regresión Logística Base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53368ac7-88ae-41f4-9763-c388c5282033",
   "metadata": {},
   "source": [
    "### Documentación de los Resultados Iniciales del Modelo Base\n",
    "\n",
    "\n",
    "**Resultados del Modelo Base: Regresión Logística**\n",
    "\n",
    "- **Accuracy:** **0.5229**. Esta métrica ha disminuido en comparación con el resultado inicial **(~0.61)**. Esto es un cambio esperado y positivo, ya que el modelo ya no está sesgado hacia la clase mayoritaria ('No Potable') y ahora intenta predecir ambas clases. La Accuracy general baja porque la tarea es más difícil, pero ahora es una métrica más honesta de su desempeño equilibrado.\n",
    "- **Precision (Clase 1 - Potable):** **0.4154**. Cuando el modelo predice \"potable\", acierta aproximadamente el **41.54%** de las veces. Indica que, aunque ya no es **0%**, todavía hay una proporción significativa de falsos positivos (predice \"potable\" cuando en realidad no lo es).\n",
    "- **Recall (Clase 1 - Potable):** **0.5509**. De todas las muestras que son realmente potables, el modelo logra identificar correctamente el 55.09%. Este valor es significativamente mejor que el **0% anterior**, mostrando que el modelo ahora es capaz de detectar más de la mitad de los casos positivos reales. Sin embargo, aún deja un **45%** de casos potables sin identificar.\n",
    "- **F1-Score (Clase 1 - Potable):** **0.4736**. Es la media armónica entre Precision y Recall. Su valor indica que, aunque el modelo ahora es funcional para la clase positiva, el equilibrio entre Precision y Recall aún es modesto.\n",
    "- **AUC-ROC:** **0.5295**. Este valor sigue siendo muy cercano a **0.5** (que representaría un clasificador aleatorio). A pesar de que el modelo ahora predice ambas clases, su capacidad para discriminar eficazmente entre las muestras \"Potables\" y \"No Potables\" es todavía muy limitada.\n",
    "\n",
    "**Análisis de Sesgo/Sobreajuste del Modelo Base:**\n",
    "\n",
    "El ajuste **class_weight='balanced'** ha corregido el problema principal de la Regresión Logística base, que era su tendencia a predecir únicamente la clase mayoritaria ('No Potable'). Esto se refleja en que **las métricas de Precision, Recall y F1-Score para la clase \"Potable\" ya no son cero.**\n",
    "\n",
    "Sin embargo, el rendimiento general del modelo sigue siendo modesto. La Accuracy ha bajado (lo cual es bueno en este contexto), pero el **AUC-ROC muy cercano a 0.5** es la señal más clara de que el modelo aún tiene una capacidad discriminatoria muy limitada. Esto sugiere que, si bien se ha abordado el sesgo por desequilibrio, el modelo de Regresión Logística, al ser lineal, puede no ser adecuado para capturar la complejidad inherente a los datos o las relaciones no lineales existentes.\n",
    "\n",
    "El modelo aún parece estar **subajustado (high bias)**. Aunque ahora intenta predecir la clase minoritaria, no está capturando suficientemente bien los patrones complejos en los datos para lograr una separación clara. No hay evidencia de sobreajuste significativo, dado el bajo rendimiento general en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d001a1f-8f57-4030-9c67-522eefa335ae",
   "metadata": {},
   "source": [
    "## 7. Ingeniería de Características (Hipótesis/Experimento)\r\n",
    "\r\n",
    "Una forma de mejorar el modelo es mediante la ingeniería de características, que implica crear nuevas características a partir de las existentes.\r\n",
    "\r\n",
    "### Hipótesis: Crear una característica de interacción entre 'ph' y 'Sulfate'.\r\n",
    "\r\n",
    "Podría ser que la combinación de niveles de pH y sulfato tenga una influencia particular en la potabilidad, que no es capturada por cada característica individualmente. Por ejemplo, ciertos rangos de pH junto con altas concentraciones de sulfato podrían indicar problemas.\r\n",
    "\r\n",
    "### Implementación de la Nueva Característica\r\n",
    "\r\n",
    "Vamos a crear una característica simple multiplicando `ph` y `Sulfate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd1589-3034-4491-a004-290bd38d58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia del DataFrame X_scaled_wq para la ingeniería de características\n",
    "X_train_fe = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test_fe = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "# Crear la nueva caractrerística: interacción entreph y Sulfate\n",
    "X_train_fe['ph_sulfate_interaction'] = X_train_fe['ph'] * X_train_fe['Sulfate']\n",
    "X_test_fe['ph_sulfate_interaction'] = X_test_fe['ph'] * X_test_fe['Sulfate']\n",
    "\n",
    "print(\"\\nPrimeras 5 filas del conjunto de entrenamiento con la nueva característica:\")\n",
    "print(X_train_fe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bb85f-c84e-47c6-9609-889ace779d11",
   "metadata": {},
   "source": [
    "### Entrenar el Modelo Base de Nuevo con la Nueva Característica\n",
    "\n",
    "Volveremos a entrenar la Regresión Logística para ver si esta nueva característica mejora el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651abb7-ac7d-4df0-bd07-813d131fbaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model_fe = LogisticRegression(random_state=42, solver='liblinear')\n",
    "log_reg_model_fe.fit(X_train_fe, y_train)\n",
    "\n",
    "print(\"\\nModelo de Regresión Logística entrenado con Ingeniería de Características.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f969bc-74cc-489d-af12-ac01c5d53ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar y Comparar Resultados\n",
    "evaluate_model(log_reg_model_fe, X_test_fe, y_test, model_name=\"Regresión Logística con FE (ph*Sulfate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08bea7-a218-41fc-a576-094298108e02",
   "metadata": {},
   "source": [
    "El modelo base Regresión Logística con class_weight='balanced:\n",
    "\n",
    "- Accuracy: 0.5229\n",
    "- Precision: 0.4154\n",
    "- Recall: 0.5509\n",
    "- F1-Score: 0.4736\n",
    "- AUC-ROC: 0.5295\n",
    "\n",
    "Modelo con Ingeniería de Características (ph*Sulfate):\n",
    "\n",
    "- Accuracy: 0.6256\n",
    "- Precision: 0.6056\n",
    "- Recall: 0.1123\n",
    "- F1-Score: 0.1894\n",
    "- AUC-ROC: 0.6050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1e8fe-c00d-448b-8b4b-f9dad271f772",
   "metadata": {},
   "source": [
    "### Documentación de la Diferencia y si Valió la Pena:\r\n",
    "\r\n",
    "**Resultados del Modelo con Ingeniería de Características (`ph*Sulfate`): Regresión Logística**\r\n",
    "\r\n",
    "- **Accuracy:** **0.6256**.\r\n",
    "- **Precision (Clase 1 - Potable):** **0.6056**. Cuando el modelo predice \"potable\", acierta aproximadamente el 60.56% de las veces. Esto es un buen valor de precisión, indicando que las predicciones positivas del modelo son relativamente fiables.\r\n",
    "- **Recall (Clase 1 - Potable):** **0.1123**. Este valor es extremadamente bajo. Indica que el modelo solo es capaz de identificar correctamente un 11.23% de todas las muestras que son realmente potables. Esto es un problema crítico si el objetivo es detectar la mayoría del agua potable.\r\n",
    "- **F1-Score (Clase 1 - Potable):** **0.1894**. Un F1-Score muy bajo, reflejo directo del bajísimo Recall. Muestra un mal equilibrio entre Precision y Recall.\r\n",
    "- **AUC-ROC:** **0.6050**. Este valor ha mejorado significativamente respecto al modelo base anterior (0.5295), indicando que la característica de interacción ha aportado una mayor capacidad de discriminación al modelo.\r\n",
    "\r\n",
    "**Comparación con el Modelo Base Ajustado (con `class_weight='balanced'`):**\r\n",
    "\r\n",
    "Al comparar este modelo con ingeniería de características con nuestro **modelo de Regresión Logística base ajustado (`class_weight='balanced'`)**, observamos lo siguiente:\r\n",
    "\r\n",
    "- **Accuracy:** Mejora sustancialmente (de 0.5229 a 0.6256).\r\n",
    "- **Precision:** Mejora notablemente (de 0.4154 a 0.6056).\r\n",
    "- **Recall:** **Empeora drásticamente** (de 0.5509 a 0.1123). Esta es la métrica más afectada negativamente, sugiriendo que el modelo, aunque ahora es más \"preciso\" cuando predice la clase 1, la encuentra mucho menos veces.\r\n",
    "- **F1-Score:** Empeora (de 0.4736 a 0.1894). El bajo Recall arrastra el F1-Score.\r\n",
    "- **AUC-ROC:** Mejora (de 0.5295 a 0.6050). Esto indica que la característica de interacción sí añade poder discriminatorio general, pero el modelo no está utilizando ese poder para mejorar el Recall de la clase minoritaria.\r\n",
    "\r\n",
    "**Análisis del Sesgo/Trade-off entre Precision y Recall:**\r\n",
    "\r\n",
    "Lo que este resultado nos muestra es un clásico **trade-off entre Precision y Recall**. Al añadir la característica `ph*Sulfate`, la Regresión Logística se vuelve más \"confiada\" en sus predicciones positivas (mayor Precision), pero al hacerlo, se vuelve mucho más conservadora y predice menos casos como positivos, lo que resulta en un Recall muy bajo. El modelo está \"perdiendo\" la mayoría de los casos de agua potable real.\r\n",
    "\r\n",
    "**¿Valió la pena la Ingeniería de Características (`ph*Sulfate`)?**\r\n",
    "\r\n",
    "En términos de **capacidad discriminatoria general (AUC-ROC) y Accuracy**, la adición de `ph*Sulfate` sí aporta una mejora para la Regresión Logística. El modelo es \"más inteligente\" en general.\r\n",
    "\r\n",
    "Sin embargo, en términos de la **capacidad para detectar la clase positiva (\"Potable\")**, que es crucial en este problema (no queremos clasificar agua potable como no potable), el **Recall cae drásticamente**. Esto significa que, para un problema donde un alto Recall de la clase positiva es importante (para evitar el consumo de agua contaminada), esta interacción por sí sola no ha sido beneficiosa para la Regresión Logística.\r\n",
    "\r\n",
    "**Conclusión:**\r\n",
    "\r\n",
    "Este experimento nos enseña que, si bien la ingeniería de características puede mejorar la capacidad general de discriminación de un modelo (como se ve en el AUC-ROC), puede no siempre resultar en un mejor equilibrio de métricas, especialmente en problemas con desequilibrio de clases y donde se busca un Recall alto para la clase minoritaria.\r\n",
    "\r\n",
    "Para el modelo de Regresión Logística, esta característica de interacción no logró un balance deseable entre Precision y Recall para la clase \"Potable\". Esto refuerza la idea de que la Regresión Logística puede ser demasiado simple para capturar adecuadamente las complejidades de este dataset, incluso con ingeniería de características. Necesitamos explorar modelos no lineales y, potencialmente, otras técnicas de manejo de desequilibrio más allá de `class_weight` (como el sobremuestreo o submuestreo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb9d9c-2fc6-4848-bcab-410aab515e52",
   "metadata": {},
   "source": [
    "## 8. Refinado del Modelo (Hipótesis/Experimentos Iterativos)\n",
    "\n",
    "Dado el bajo rendimiento de la Regresión Logística (incluso con `class_weight='balanced'`) y el compromiso indeseable en el Recall introducido por la ingeniería de características de `ph*Sulfate`, es momento de probar algoritmos más potentes y luego optimizar sus hiperparámetros.\n",
    "\n",
    "Para los siguientes experimentos, utilizaremos el dataset **escalado**. Con respecto a la característica de interacción `ph*Sulfate`, si bien mostró una mejora en el AUC-ROC general (pasando de 0.5295 a 0.6050) y la Accuracy (de 0.5229 a 0.6256) para la Regresión Logística, su introducción deterioró drásticamente el Recall de la clase \"Potable\" (pasando de 0.5509 a 0.1123).\n",
    "Considerando la importancia crítica de un Recall alto para la detección de agua potable (minimizar falsos negativos), por ahora **optaremos por no incluir la característica `ph*Sulfate` en los modelos siguientes**, para mantener la base de comparación limpia y enfocarnos en el rendimiento en Recall con algoritmos más complejos. Sin embargo, no se descarta revisitar la ingeniería de características en futuras iteraciones si los modelos más potentes no alcanzan el rendimiento deseado. Volvemos a trabajar con el `X_scaled` original.\n",
    "\n",
    "### Hipótesis 1: Probar otro algoritmo - Random Forest Classifier\n",
    "\n",
    "El Random Forest es un algoritmo de ensemble basado en árboles de decisión que suele ofrecer un buen rendimiento \"fuera de la caja\" y es robusto al desequilibrio de clases y outliers.\n",
    "\n",
    "### Justificación de la Elección\n",
    "\n",
    "- **No linealidad**: Puede capturar relaciones no lineales complejas entre las características y la variable objetivo, algo que la Regresión Logística no puede hacer.\n",
    "- **Robustez**: Menos sensible a outliers y al desequilibrio de clases en comparación con otros modelos.\n",
    "- **Importancia de características**: Permite extraer la importancia de las características, lo cual es útil para la interpretabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e3382-597a-4cd9-a16f-3e8a6142481a",
   "metadata": {},
   "source": [
    "### Entrenar y Evaluar Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d40cb8-2890-4389-ac64-0ef64d557772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train) # Usamos X_train original (escalado, sin la nueva FE)\n",
    "\n",
    "print(\"Modelo Random Forest Classifier entrenado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b57fa-41c8-49b3-a91e-68a681fa957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf_model, X_test, y_test, model_name=\"Random Forest Classifier (Modelo_v2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68f8d7-3bb8-4ad9-83af-91f967467dab",
   "metadata": {},
   "source": [
    "Últimos resultados:\n",
    "\n",
    "- **Random Forest Classifier (Modelo_v2) con `class_weight='balanced'`:**\n",
    "    - Accuracy: 0.6450\n",
    "    - Precision: 0.6012\n",
    "    - Recall: 0.2637\n",
    "    - F1-Score: 0.3666\n",
    "    - AUC-ROC: 0.6604\n",
    "\n",
    "Vamos a comparar esto con los modelos anteriores:\n",
    "\n",
    "- **Regresión Logística Base (con `class_weight='balanced'`):**\n",
    "    - Accuracy: 0.5229\n",
    "    - Precision: 0.4154\n",
    "    - Recall: 0.5509\n",
    "    - F1-Score: 0.4736\n",
    "    - AUC-ROC: 0.5295\n",
    "- **Regresión Logística (con Ingeniería de Características `ph*Sulfate`):**\n",
    "    - Accuracy: 0.6256\n",
    "    - Precision: 0.6056\n",
    "    - Recall: 0.1123\n",
    "    - F1-Score: 0.1894\n",
    "    - AUC-ROC: 0.6050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3af27e-8dca-4152-8225-b94c553c01bd",
   "metadata": {},
   "source": [
    "### Documentación de la Diferencia y si Valió la Pena:\n",
    "\n",
    "**Resultados del Modelo: Random Forest Classifier (Modelo_v2) - (con `class_weight='balanced'`)**\n",
    "\n",
    "- **Accuracy:** **0.6450**. Este valor es una mejora gradual con respecto a los modelos de Regresión Logística anteriores.\n",
    "- **Precision (Clase 1 - Potable):** **0.6012**. Una buena precisión, similar o ligeramente inferior a la Regresión Logística con Ingeniería de Características. Indica que cuando el modelo predice \"potable\", acierta en un 60.12% de los casos.\n",
    "- **Recall (Clase 1 - Potable):** **0.2637**. Este es el punto más débil. Aunque mejor que el Recall del modelo de Regresión Logística con Ingeniería de Características (0.1123), es significativamente más bajo que el Recall del modelo de Regresión Logística base ajustado (0.5509). Esto significa que el Random Forest actual solo está identificando aproximadamente una cuarta parte de todas las muestras de agua que son realmente potables.\n",
    "- **F1-Score (Clase 1 - Potable):** **0.3666**. Refleja el compromiso entre Precision y Recall. Es un F1-Score bajo, indicando que el modelo aún no encuentra un equilibrio efectivo para la clase minoritaria.\n",
    "- **AUC-ROC:** **0.6604**. Este es el valor más alto obtenido hasta ahora en el proyecto, lo que sugiere una mejor capacidad general del Random Forest para distinguir entre las dos clases, a pesar de las limitaciones en Recall.\n",
    "\n",
    "**Comparación con los Modelos Anteriores (Regresión Logística Base Ajustada y con Ingeniería de Características):**\n",
    "\n",
    "El **Random Forest Classifier (Modelo_v2)**, con `class_weight='balanced'`, representa una **mejora en la capacidad discriminatoria general (AUC-ROC) y en la Accuracy** con respecto a las iteraciones previas de la Regresión Logística.\n",
    "\n",
    "- **Respecto al Modelo Base de Regresión Logística (ajustado):**\n",
    "    - **Accuracy y AUC-ROC:** Mejoran sustancialmente (de 0.5229 a 0.6450 para Accuracy; de 0.5295 a 0.6604 para AUC-ROC).\n",
    "    - **Precision:** Mejora (de 0.4154 a 0.6012).\n",
    "    - **Recall y F1-Score:** Empeoran (Recall de 0.5509 a 0.2637; F1-Score de 0.4736 a 0.3666). Esto sugiere un cambio en el \"sesgo\" del modelo, priorizando la precisión sobre la capacidad de detección.\n",
    "- **Respecto al Modelo de Regresión Logística con Ingeniería de Características (`ph*Sulfate`):**\n",
    "    - **Accuracy y AUC-ROC:** Mejora (de 0.6256 a 0.6450 para Accuracy; de 0.6050 a 0.6604 para AUC-ROC).\n",
    "    - **Precision:** Muy similar (0.6056 vs 0.6012).\n",
    "    - **Recall y F1-Score:** Mejoran (Recall de 0.1123 a 0.2637; F1-Score de 0.1894 a 0.3666), indicando que el Random Forest es más capaz de manejar el Recall incluso sin la característica de interacción.\n",
    "\n",
    "**Análisis del Rendimiento Actual del Random Forest:**\n",
    "\n",
    "Aunque el Random Forest demuestra ser un modelo intrínsecamente más potente que la Regresión Logística para este problema (evidenciado por el mejor AUC-ROC), su rendimiento actual aún presenta un **desequilibrio significativo entre Precision y Recall** para la clase \"Potable\". La alta Precision es buena, pero un Recall de ~26% es críticamente bajo si el objetivo principal es asegurar que se detecte la mayor cantidad posible de agua potable. El modelo es \"demasiado conservador\" al predecir la potabilidad.\n",
    "\n",
    "**Decisión y Próximos Pasos:**\n",
    "\n",
    "El Random Forest es el modelo con mayor **potencial** hasta ahora, dadas sus mejoras en AUC-ROC y su capacidad para manejar la no linealidad. Sin embargo, su configuración actual por defecto no es suficiente para un problema donde el Recall de la clase positiva es tan importante.\n",
    "\n",
    "Procederemos a **optimizar los hiperparámetros de este modelo Random Forest Classifier**. Nuestro objetivo principal en la optimización será mejorar el **Recall y el F1-Score** para la clase \"Potable\" sin sacrificar excesivamente la Precision y manteniendo el AUC-ROC. Esto se logrará mediante técnicas de búsqueda como `GridSearchCV` o `RandomizedSearchCV`, que nos permitirán explorar diferentes combinaciones de parámetros (`n_estimators`, `max_depth`, `min_samples_split`, etc.) y encontrar la configuración óptima para nuestros objetivos de rendimiento.\n",
    "\n",
    "Adicionalmente, y si la optimización de hiperparámetros no es suficiente, podríamos **revisitar la ingeniería de características** y probar la característica `ph*Sulfate` (o crear otras) con el Random Forest optimizado, ya que un modelo más robusto podría aprovecharla de una forma más beneficiosa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a09a0-bc56-4111-9049-91921313f51c",
   "metadata": {},
   "source": [
    "### Hipótesis 2: Optimización de hiperparámetros del mejor modelo (Random Forest)\r\n",
    "\r\n",
    "Hemos identificado al Random Forest como el modelo con el mayor potencial hasta ahora, mostrando una mejor capacidad discriminatoria general (AUC-ROC) en comparación con la Regresión Logística. Ahora, utilizaremos `GridSearchCV` para encontrar la mejor combinación de hiperparámetros y optimizar su rendimiento, especialmente buscando mejorar el Recall y el F1-Score para la clase \"Potable\".\r\n",
    "\r\n",
    "`GridSearchCV` realizará una búsqueda exhaustiva sobre un conjunto de valores de parámetros especificados, utilizando validación cruzada.\r\n",
    "\r\n",
    "### Proceso de Optimización con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acda8d-e5d3-4d7c-8d2d-1bdc0f4cc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cuadrícula de parámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'class_weight': ['balanced'] # Importante mantener esto para el desequilibrio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030d656-03e3-4c7a-9d8c-d2f11f64c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar GridSearchCV\n",
    "# cv=5 para K-Fold Cross Validation con 5 folds en el entrenamiento\n",
    "# scoring='roc_auc' porque es una métrica robusta al desequilibrio de clases y un buen indicador general\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "print(\"Iniciando búsqueda de hiperparámetros para Random Forest...\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"\\nBúsqueda de hiperparámetros completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbed83d-4205-4b8f-9be8-16dcc394bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los mejores parámetros encontrados\n",
    "print(\"\\nMejores parámetros encontrados por GridSearchCV:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6efb61-6bb7-44e7-b74c-1cc89504700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e6592-3463-473a-88ee-66cf1c68d576",
   "metadata": {},
   "source": [
    "### Entrenar el Modelo con los Mejores Hiperparámetros Encontrados\n",
    "\n",
    "El `best_estimator_` de `GridSearchCV` ya está entrenado en el conjunto de entrenamiento completo (o en los folds de CV si no se especifica `refit=True`, que es el valor por defecto).\n",
    "\n",
    "### Evaluar y Comparar sus Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775167e-2f62-4696-affb-212bd51eb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_rf_model, X_test, y_test, model_name=\"Random Forest Optimizado (Modelo_v3 - GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af02eaa-885d-49ce-be9f-dd27fe885aa5",
   "metadata": {},
   "source": [
    "### Justificación de por qué esta es la \"mejor\" versión del modelo hasta este punto:\n",
    "\n",
    "**Resultados del Modelo: Random Forest Optimizado (Modelo_v3 - GridSearchCV)**\n",
    "\n",
    "- **Accuracy:** **0.6562**. Una mejora modesta respecto al Random Forest sin optimizar (0.6450) y a los modelos de Regresión Logística anteriores.\n",
    "- **Precision (Clase 1 - Potable):** **0.6077**. Ligeramente superior a la Precision del Random Forest sin optimizar (0.6012), indicando que el modelo es mínimamente más fiable cuando predice \"potable\".\n",
    "- **Recall (Clase 1 - Potable):** **0.3316**. Esta es una mejora notable y positiva respecto al Recall del Random Forest sin optimizar (0.2637) y al Recall de la Regresión Logística con Ingeniería de Características (0.1123). Sin embargo, sigue siendo significativamente más bajo que el Recall del modelo de Regresión Logística base ajustado (0.5509), lo que implica que el modelo aún no detecta una gran parte del agua realmente potable.\n",
    "- **F1-Score (Clase 1 - Potable):** **0.4291**. También una mejora positiva respecto al F1-Score del Random Forest sin optimizar (0.3666), reflejando el aumento en el Recall.\n",
    "- **AUC-ROC:** **0.6656**. Este es el valor más alto de AUC-ROC obtenido hasta ahora, lo que sugiere que la optimización ha mejorado ligeramente la capacidad general de discriminación del modelo Random Forest.\n",
    "\n",
    "**Comparación con las versiones anteriores:**\n",
    "\n",
    "El Random Forest Optimizado (Modelo_v3) ha logrado **mejoras marginales pero consistentes** en la mayoría de las métricas en comparación con el Random Forest sin optimizar (Modelo_v2), especialmente en el **Recall y F1-Score**, que son cruciales para la clase minoritaria. También mantiene la ventaja en Accuracy y AUC-ROC sobre las versiones de Regresión Logística.\n",
    "\n",
    "- **Respecto al Random Forest sin optimizar (Modelo_v2):**\n",
    "    - **Accuracy:** Mejora de 0.6450 a 0.6562.\n",
    "    - **Precision:** Mejora de 0.6012 a 0.6077.\n",
    "    - **Recall:** Mejora de 0.2637 a 0.3316.\n",
    "    - **F1-Score:** Mejora de 0.3666 a 0.4291.\n",
    "    - **AUC-ROC:** Mejora de 0.6604 a 0.6656.\n",
    "- **Respecto a los modelos de Regresión Logística:**\n",
    "    - Sigue superando a la Regresión Logística en Accuracy y AUC-ROC.\n",
    "    - Supera significativamente el Recall y F1-Score de la Regresión Logística con FE.\n",
    "    - Sin embargo, el Recall del Modelo_v3 sigue siendo inferior al del modelo de Regresión Logística base ajustado (0.5509 vs 0.3316), lo que indica que, a pesar de la optimización, aún hay un compromiso en la detección de casos positivos.\n",
    "\n",
    "**Justificación de ser la \"mejor\" versión hasta este punto:**\n",
    "\n",
    "Esta es la mejor versión del modelo hasta ahora porque:\n",
    "\n",
    "- **Rendimiento Mejorado y más Equilibrado:** Ha superado consistentemente las versiones anteriores en métricas clave como F1-Score y AUC-ROC, y ha logrado un aumento notable en el Recall de la clase minoritaria, acercándose a un equilibrio más deseable entre Precision y Recall.\n",
    "- **Optimización Sistemática:** Se utilizó `GridSearchCV`, una técnica robusta para explorar el espacio de hiperparámetros de manera sistemática, asegurando que se encontraron los parámetros que maximizan el rendimiento (en este caso, ROC AUC), lo cual es crucial para problemas con desequilibrio de clases.\n",
    "- **Generalización Potencial:** Al haber sido optimizado con validación cruzada, es más probable que este modelo generalice bien a datos no vistos, en comparación con un modelo con hiperparámetros por defecto o ajustado manualmente.\n",
    "- **Límites Observados:** Los resultados sugieren que, con las características actuales y el Random Forest, nos estamos acercando a un límite de rendimiento para este dataset. Es posible que para mejoras sustanciales se requiera una ingeniería de características más profunda, la incorporación de datos adicionales, o la exploración de modelos aún más avanzados (como GBMs con un ajuste más fino) o ajustado manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ccf46-9414-4f44-8274-ab618ed8d718",
   "metadata": {},
   "source": [
    "### Hipótesis 3: Probar otro algoritmo - LightGBM Classifier\r\n",
    "\r\n",
    "Dado que, a pesar de la optimización de hiperparámetros, el Random Forest aún presenta un Recall mejorable y un AUC-ROC que podría ser superior, exploraremos un algoritmo de Gradient Boosting: LightGBM. Los modelos de Gradient Boosting suelen ser aún más potentes que los Random Forest en la captura de patrones complejos.\r\n",
    "\r\n",
    "### Justificación de la Elección\r\n",
    "\r\n",
    "- **Mayor Potencia Predictiva:** Los algoritmos de Gradient Boosting construyen árboles de decisión de forma secuencial, corrigiendo los errores de los árboles anteriores, lo que a menudo resulta en una mayor precisión que los modelos de bagging como Random Forest.\r\n",
    "- **Eficiencia y Escalabilidad:** LightGBM es conocido por su alta velocidad de entrenamiento y bajo consumo de memoria, lo que lo hace ideal para conjuntos de datos grandes y para iteraciones rápidas.\r\n",
    "- **Manejo de No Linealidad y Complejidad:** Al igual que Random Forest, puede capturar relaciones no lineales complejas, pero con un enfoque diferente que puede ser más efectivo en algunos datasets.\r\n",
    "- **Robustez al Desequilibrio:** Permite ajustar los pesos de las clases o el umbral de decisión para manejar el desequilibrio de clases, similar a otros modelos.\r\n",
    "\r\n",
    "### Entrenamiento del Modelo LightGBM Base\r\n",
    "\r\n",
    "Entrenaremos una versión base de LightGBM utilizando los datos escalados (`X_train`, `y_train`) para ver su rendimiento inicial antes de considerar la optimización de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9882b06-8271-41b9-b397-83ae3788f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar el modelo LightGBM\n",
    "# Usamos objective='binary' para clasificación binaria\n",
    "# is_unbalance=True es una forma de LightGBM para manejar el desequilibrio de clases\n",
    "# random_state para reproducibilidad\n",
    "lgbm_model = lgb.LGBMClassifier(objective='binary', is_unbalance=True, random_state=42)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo LightGBM Classifier base entrenado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056e270-fa5d-4eed-abdc-f6665e53698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del Modelo LightGBM Base\n",
    "evaluate_model(lgbm_model, X_test, y_test, model_name=\"LightGBM Classifier (Modelo_v4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64c4ce-a935-4f50-bb65-0aca66ad0bcb",
   "metadata": {},
   "source": [
    "### Resultados del Modelo: LightGBM Classifier (Modelo_v4)\r\n",
    "\r\n",
    "- **Accuracy:** **0.6429**. Similar al Random Forest sin optimizar (0.6450) y ligeramente inferior al Random Forest optimizado (0.6562).\r\n",
    "- **Precision (Clase 1 - Potable):** **0.5476**. Inferior a las Precisiones del Random Forest (0.6012 y 0.6077), pero superior a la de la Regresión Logística base (0.4154).\r\n",
    "- **Recall (Clase 1 - Potable):** **0.4804*. ¡Este es un resultado c.ave! Ha mejorado significativamente respecto al Recall de ambos modelos Random Forest (0.2637 y 0.3316) y se acerca más al Recall de la Regresión Logística base (0.5509). Esto indica que LightGBM es mucho mejor detectando los casos de agua potable real.\r\n",
    "- **F1-Score (Clase 1 - Potable):** **0.5118**. Este es el F1-Score más alto obtenido hasta ahora en el proyecto (superando el 0.4291 del Random Forest optimizado y el 0.4736 de la Regresión Logística base). Indica un mejor equilibrio general entre Precision y Recall para la clase minoritaria.\r\n",
    "- **AUC-ROC:** **0.6496**. Ligeramente inferior al AUC-ROC del Random Forest optimizado (0.6656), pero sigue siendo un valor razonable que muestra capacidad discriminatoria.\r\n",
    "\r\n",
    "### Comparación con las versiones anteriores:\r\n",
    "\r\n",
    "El **LightGBM Classifier (Modelo_v4)**, incluso en su configuración base, demuestra un **balance de rendimiento muy prometedor**.\r\n",
    "\r\n",
    "- Aunque su **Accuracy** y **AUC-ROC** son ligeramente inferiores a los del Random Forest optimizado, el **Recall** y el **F1-Score** para la clase \"Potable\" han mejorado sustancialmente.\r\n",
    "    - **Recall:** De 0.3316 (RF Optimizado) a **0.4804** (LightGBM).\r\n",
    "    - **F1-Score:** De 0.4291 (RF Optimizado) a **0.5118** (LightGBM).\r\n",
    "\r\n",
    "Este trade-off es a menudo deseable en problemas de clasificación de potabilidad, donde un Recall alto (detectar la mayor cantidad posible de agua potable) es crítico, incluso si eso implica una ligera disminución en la Precision o la Accuracy general.\r\n",
    "\r\n",
    "### Decisión y Próximos Pasos:\r\n",
    "\r\n",
    "El LightGBM ha demostrado ser el modelo con el **mejor equilibrio de métricas para la clase positiva** hasta ahora, logrando el F1-Score más alto y un Recall significativamente mejorado. Su capacidad para detectar agua potable es superior a la del Random Forest.\r\n",
    "\r\n",
    "El siguiente paso lógico es **optimizar los hiperparámetros de este modelo LightGBM Classifier**. Buscaremos refinar aún más su rendimiento, intentando mejorar su AUC-ROC y Accuracy sin sacrificar el valioso Recall y F1-Score que ya ha logrado. Utilizaremos técnicas de búsqueda como `GridSearchCV` o `RandomizedSearchCV` para encontrar la combinación óptima de parámetros para LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bd0e0-29ab-4900-ae6f-cfbd992a0b55",
   "metadata": {},
   "source": [
    "### Hipótesis 4: Optimización de hiperparámetros del modelo LightGBM\r\n",
    "\r\n",
    "Nuestro modelo LightGBM base (Modelo_v4) ha demostrado ser el más prometedor hasta ahora, logrando el F1-Score más alto y un Recall significativamente mejorado para la clase \"Potable\". El siguiente paso es optimizar sus hiperparámetros para intentar mejorar aún más su capacidad predictiva y discriminatoria, buscando el mejor equilibrio entre todas las métricas.\r\n",
    "\r\n",
    "Utilizaremos `GridSearchCV` para encontrar la combinación óptima de hiperparámetros para nuestro modelo LightGBM, explorando un rango de valores para parámetros clave.\r\n",
    "\r\n",
    "### Proceso de Optimización con GridSearchCV para LightGBM\r\n",
    "\r\n",
    "Definiremos una cuadrícula de parámetros (`param_grid`) que incluirá valores a probar para el número de estimadores (`n_estimators`), la profundidad máxima de los árboles (`max_depth`), la tasa de aprendizaje (`learning_rate`), y quizás el número de hojas (`num_leaves`). Es crucial mantener el parámetro `is_unbalance=True` (o un equivalente `scale_pos_weight`) para que `GridSearchCV` también pruebe con la característica de manejo de desequilibrio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a5249-e934-4d3e-8e93-cab730b47e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cuadrícula de parámetros para GridSearchCV\n",
    "# Estos son parámetros de LightGBM que influyen en el rendimiento y la complejidad\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200, 300], # Número de árboles\n",
    "    'learning_rate': [0.05, 0.1, 0.15], # Tasa de aprendizaje\n",
    "    'num_leaves': [20, 31, 40], # Número máximo de hojas por árbol\n",
    "    'max_depth': [-1, 10, 20], # Profundidad máxima del árbol (-1 significa sin límite)\n",
    "    'min_child_samples': [20, 30], # Mínimo número de datos en una hoja\n",
    "    'objective': ['binary'], # Mantener el objetivo binario\n",
    "    'is_unbalance': [True], # ¡Importante mantener para el manejo del desequilibrio!\n",
    "    'random_state': [42] # Para reproducibilidad\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17bd25-885c-4995-a288-68e5110ee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar GridSearchCV\n",
    "# cv=5 para K-Fold Cross Validation con 5 folds en el entrenamiento\n",
    "# scoring='roc_auc' como métrica principal para la optimización\n",
    "# n_jobs=-1 \n",
    "grid_search_lgbm = GridSearchCV(lgb.LGBMClassifier(), param_grid_lgbm, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1014d1e-21fc-4c5e-b16e-5cef3e520f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iniciando búsqueda de hiperparámetros para LightGBM...\")\n",
    "grid_search_lgbm.fit(X_train, y_train)\n",
    "print(\"\\nBúsqueda de hiperparámetros de LightGBM completada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9c057-807e-4074-9fad-d9355fdc15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los mejores parámetros encontrados\n",
    "print(\"\\nMejores parámetros encontrados por GridSearchCV para LightGBM:\")\n",
    "print(grid_search_lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53215d4d-7e60-4ea2-a239-905dfea40247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo LightGBM\n",
    "best_lgbm_model = grid_search_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb8e19-a5d3-48b8-b338-7e2e3223d4ac",
   "metadata": {},
   "source": [
    "### Entrenar el Modelo con los Mejores Hiperparámetros Encontrados\n",
    "\n",
    "El `best_estimator_` de `grid_search_lgbm` ya está entrenado en el conjunto de entrenamiento completo (o en los folds de CV si no se especifica `refit=True`, que es el valor por defecto).\n",
    "\n",
    "### Evaluar y Comparar sus Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b36ced-c7e2-4bf7-9e16-0491b8ecbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_lgbm_model, X_test, y_test, model_name=\"LightGBM Optimizado (Modelo_v5 - GridSearchCV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11678c04-c33e-4075-ab52-bb2821cd840d",
   "metadata": {},
   "source": [
    "### Justificación de por qué esta es la \"mejor\" versión del modelo hasta este punto:\n",
    "\n",
    "**Resultados del Modelo: LightGBM Optimizado (Modelo_v5 - GridSearchCV)**\n",
    "\n",
    "- **Accuracy:** **0.6399**. Ligeramente inferior al LightGBM base (0.6429) y al Random Forest optimizado (0.6562).\n",
    "- **Precision (Clase 1 - Potable):** **0.5428**. Ligeramente inferior al LightGBM base (0.5476).\n",
    "- **Recall (Clase 1 - Potable):** **0.4804**. **Exactamente el mismo** que el LightGBM base. Sigue siendo superior al Recall de los modelos Random Forest, pero muy similar al de la Regresión Logística base.\n",
    "- **F1-Score (Clase 1 - Potable):** **0.5097**. Ligeramente inferior al LightGBM base (0.5118).\n",
    "- **AUC-ROC:** **0.6610**. Una mejora marginal respecto al LightGBM base (0.6496), y ahora es el valor de AUC-ROC más alto obtenido hasta el momento (superando el 0.6656 del Random Forest optimizado por un margen mínimo, si es que es realmente significativo).\n",
    "\n",
    "**Mejores parámetros encontrados por GridSearchCV para LightGBM:** *`{'is_unbalance': True, 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 31}`*\n",
    "\n",
    "**Análisis de la Optimización de LightGBM:**\n",
    "\n",
    "Los resultados de la optimización con `GridSearchCV` para LightGBM muestran que las mejoras sobre el modelo LightGBM base (Modelo_v4) fueron **marginales en la mayoría de las métricas**, e incluso hubo ligeras disminuciones en Accuracy, Precision y F1-Score. La métrica clave del Recall se mantuvo idéntica. La única mejora discernible fue en el AUC-ROC, que aumentó ligeramente.\n",
    "\n",
    "Esto sugiere que:\n",
    "\n",
    "1. **El modelo LightGBM base (Modelo_v4) ya estaba muy cerca de su rendimiento óptimo** para el dataset y el rango de hiperparámetros explorado.\n",
    "2. **Podríamos estar alcanzando un \"techo\" de rendimiento** con las características actuales del dataset y los modelos ensayados. Las propiedades fisicoquímicas proporcionadas podrían no contener suficiente información discriminatoria adicional para clasificar la potabilidad del agua con una precisión mucho mayor de la que ya hemos logrado.\n",
    "\n",
    "**Justificación de ser la \"mejor\" versión hasta este punto:**\n",
    "\n",
    "Considerando el conjunto de métricas, el **LightGBM optimizado (Modelo_v5) o incluso el LightGBM base (Modelo_v4)** representan el mejor compromiso hasta ahora, especialmente por su **alto Recall y F1-Score** en la clase \"Potable\", que son críticos para este problema. Si bien el Random Forest optimizado (`Modelo_v3`) tenía un Accuracy y un AUC-ROC marginalmente superiores, su Recall era significativamente inferior.\n",
    "\n",
    "Aunque la optimización no produjo un salto dramático, ha permitido confirmar que LightGBM es un modelo robusto para este problema y que sus parámetros por defecto ya ofrecen un rendimiento muy cercano al óptimo para el conjunto de datos dado.\n",
    "\n",
    "**Conclusión preliminar antes de la conclusión final del proyecto:**\n",
    "\n",
    "Hemos explorado modelos lineales (Regresión Logística) y no lineales basados en árboles (Random Forest, LightGBM), aplicando técnicas para el desequilibrio de clases y optimización de hiperparámetros. Los resultados indican que, si bien hemos logrado mejoras iterativas, el rendimiento general (especialmente en Recall y F1-Score para la clase minoritaria) parece estabilizarse en un rango modesto. Esto sugiere que para alcanzar niveles de rendimiento significativamente más altos, podríamos necesitar:\n",
    "\n",
    "- **Ingeniería de características más avanzada:** Crear nuevas características más complejas o transformaciones no lineales que los modelos puedan aprovechar.\n",
    "- **Recopilación de datos adicionales:** Si fuera posible, añadir más características al dataset o expandir el tamaño del mismo.\n",
    "- **Modelos o técnicas de ML más avanzadas:** Aunque LightGBM es muy potente, podrían explorarse ensambles de modelos o arquitecturas de redes neuronales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89963a36-f0bb-4637-b695-86cab43f1445",
   "metadata": {},
   "source": [
    "### Hipótesis 5: Uso de SMOTE con LightGBM Optimizado\n",
    "\n",
    "A pesar de la optimización de hiperparámetros, los modelos LightGBM y Random Forest han mostrado un rendimiento estabilizado y un Recall para la clase \"Potable\" que, aunque mejorado, aún podría ser más alto. Dada la naturaleza desequilibrada del dataset, se propone aplicar una técnica de sobremuestreo sintético (SMOTE) en el conjunto de entrenamiento para intentar mejorar la capacidad del modelo para identificar la clase minoritaria.\n",
    "\n",
    "**Objetivo:** Aumentar el Recall y el F1-Score para la clase \"Potable\" sin comprometer excesivamente la Precision y el AUC-ROC.\n",
    "\n",
    "### Justificación de la Elección\n",
    "\n",
    "- **Abordar el Desequilibrio Activamente:** A diferencia de `class_weight` o `is_unbalance` (que ajustan los pesos durante el entrenamiento), SMOTE genera explícitamente nuevas muestras, proporcionando más ejemplos a la clase minoritaria para que el modelo aprenda.\n",
    "- **Mejora del Recall:** Es una técnica muy conocida y efectiva para mejorar la capacidad de los clasificadores para detectar la clase minoritaria, lo cual es crucial para la detección de agua potable.\n",
    "- **Complemento a la Optimización:** Se aplicará SMOTE antes de entrenar el modelo LightGBM con los mejores hiperparámetros ya encontrados, para ver si un dataset balanceado le permite explotar mejor su potencial.\n",
    "\n",
    "### Proceso de Aplicación de SMOTE y Entrenamiento de LightGBM\n",
    "\n",
    "Es crucial aplicar SMOTE **solo al conjunto de entrenamiento** después de la división de datos para evitar la fuga de información (data leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933f5f7-c83e-457a-8f52-f45dc903e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE solo al conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754deb5-c138-4363-9f6f-1b4309feb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Proporción de clases en y_train ANTES de SMOTE:\\n{pd.Series(y_train).value_counts(normalize=True)}\")\n",
    "print(f\"Proporción de clases en y_train DESPUÉS de SMOTE:\\n{pd.Series(y_train_smote).value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05a3a6-cdb7-40b1-9096-9ac6144c570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el mejor modelo LightGBM encontrado (best_lgbm_model de la Hipótesis 4)\n",
    "# Nos aseguramos de usar 'best_lgbm_model' que ya tiene los hiperparámetros óptimos\n",
    "# Es importante re-entrenar este modelo con los datos balanceados por SMOTE\n",
    "best_lgbm_model_smote = best_lgbm_model # Creamos una copia para el re-entrenamiento\n",
    "best_lgbm_model_smote.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e97b3-2da3-4b59-8441-c8fbe3865f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modelo LightGBM Optimizado entrenado con datos balanceados por SMOTE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc9863-d4e9-4846-afbc-de5fc822f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del Modelo LightGBM con SMOTE\n",
    "evaluate_model(best_lgbm_model_smote, X_test, y_test, model_name=\"LightGBM Optimizado + SMOTE(Modelo_v6)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a08da5-7597-40c2-a3eb-d543137c2525",
   "metadata": {},
   "source": [
    "### Resultados del Modelo: LightGBM Optimizado + SMOTE (Modelo_v6)\n",
    "\n",
    "- **Accuracy:** **0.6124**. Ligeramente inferior a las versiones de LightGBM sin SMOTE.\n",
    "- **Precision (Clase 1 - Potable):** **0.5027**. Inferior a la Precision de las versiones de LightGBM sin SMOTE.\n",
    "- **Recall (Clase 1 - Potable):** **0.4935**. Ligeramente superior al Recall de las versiones de LightGBM sin SMOTE (0.4804), cumpliendo el objetivo de SMOTE de aumentar la detección de la clase minoritaria.\n",
    "- **F1-Score (Clase 1 - Potable):** **0.4980**. Ligeramente inferior a las versiones de LightGBM sin SMOTE (donde el F1-Score fue ~0.51).\n",
    "- **AUC-ROC:** **0.6491**. Muy similar al LightGBM base (0.6496) y ligeramente inferior al LightGBM optimizado (0.6610) y al Random Forest optimizado (0.6656).\n",
    "\n",
    "### Análisis de la Aplicación de SMOTE:\n",
    "\n",
    "La aplicación de SMOTE logró su objetivo de **incrementar marginalmente el Recall** de la clase \"Potable\". Sin embargo, esta mejora vino acompañada de una **disminución en la Precision y la Accuracy general**, lo que resultó en un F1-Score global ligeramente inferior. El AUC-ROC también se mantuvo en un rango similar.\n",
    "\n",
    "Esto indica un trade-off clásico: al forzar al modelo a ser más sensible a la clase minoritaria (mejor Recall), se vuelve más propenso a cometer falsos positivos (menor Precision). La modesta mejora en el Recall y el ligero descenso en el F1-Score sugieren que, con las características actuales, el dataset podría no permitir un aumento sustancial en la detectabilidad de la clase minoritaria sin un sacrificio considerable en otras métricas.\n",
    "\n",
    "**Justificación de por qué esta es (o no es) la \"mejor\" versión del modelo hasta este punto:**\n",
    "\n",
    "El **LightGBM Optimizado + SMOTE (Modelo_v6)** demuestra una capacidad mejorada para detectar casos de agua potable (Recall), lo cual es valioso. Sin embargo, este incremento en Recall se obtiene a expensas de una menor Precision y una ligera disminución en el F1-Score.\n",
    "\n",
    "Comparado con el **LightGBM Optimizado (Modelo_v5)**, el Modelo_v6 no representa una mejora neta y clara en términos de equilibrio general (F1-Score) o capacidad discriminatoria (AUC-ROC). Más bien, ofrece un perfil de rendimiento diferente: mayor Recall a costa de menor Precision.\n",
    "\n",
    "**Conclusión Preliminar y Próximos Pasos:**\n",
    "\n",
    "Hemos explorado una amplia gama de enfoques: modelos lineales, modelos basados en árboles (Random Forest, LightGBM), optimización de hiperparámetros y técnicas de balanceo de clases (class_weight, SMOTE). Los resultados sugieren que, con las características actuales del dataset, el rendimiento de los modelos se ha estabilizado en un rango modesto, con el **LightGBM Optimizado (Modelo_v5)** ofreciendo el mejor balance general de métricas (especialmente F1-Score y AUC-ROC), y el **LightGBM Optimizado + SMOTE (Modelo_v6)** ofreciendo el mejor Recall, aunque con un F1-Score ligeramente inferior.\n",
    "\n",
    "Considerando que hemos probado varias hipótesis sólidas y explorado técnicas comunes para mejorar el rendimiento, es probable que estemos **cerca del techo de rendimiento alcanzable con este dataset y las características existentes**. Para obtener mejoras significativamente mayores, sería necesario:\n",
    "\n",
    "- **Ingeniería de características más avanzada:** Crear interacciones o transformaciones no lineales de mayor complejidad, o incluso combinar características de formas más inteligentes.\n",
    "- **Adición de más datos o características:** Si fuera posible, integrar información adicional que no está presente en el dataset actual.\n",
    "- **Exploración de modelos más allá de los GBMs:** Aunque los GBMs son muy potentes, se podrían considerar ensambles más complejos (stacking) o, en un contexto diferente, arquitecturas de redes neuronales profundas si la complejidad y los datos lo justifican."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea11ccb-f59e-4fee-a475-88b4f01eca8f",
   "metadata": {},
   "source": [
    "### Hipótesis 6: Reintroducción de la Característica de Ingeniería `ph*Sulfate` con LightGBM Optimizado\r\n",
    "\r\n",
    "En iteraciones anteriores, la característica de ingeniería `ph*Sulfate` (`ph_sulfate_interaction`) se descartó para modelos no lineales debido a su impacto negativo en el Recall de la Regresión Logística. Sin embargo, los modelos basados en árboles como Random Forest y LightGBM son inherentemente más capaces de manejar relaciones no lineales y complejas entre características.\r\n",
    "\r\n",
    "Se propone reintroducir esta característica en el conjunto de datos y entrenar con ella el **LightGBM optimizado (Modelo_v5)**, para determinar si un modelo no lineal y robusto puede aprovechar esta información de interacción de una manera beneficiosa, sin los mismos compromisos observados en el modelo lineal.\r\n",
    "\r\n",
    "**Objetivo:** Evaluar si la característica `ph_sulfate_interaction` puede mejorar el rendimiento general del mejor modelo (LightGBM Optimizado), buscando una mejora en el AUC-ROC o en el F1-Score, sin una penalización severa en el Recall.\r\n",
    "\r\n",
    "### Proceso de Reintroducción de la Característica y Entrenamiento\r\n",
    "\r\n",
    "Primero, necesitamos volver a crear el dataset `X_scaled` incluyendo la característica `ph*Sulfate` desde el inicio, antes de la división en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd635c7a-f988-4a61-baf6-6b20aef40682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carga del Dataset (Directa y Simple) ---\n",
    "file_path = 'water_potability.csv'\n",
    "water_quality = pd.read_csv(file_path)\n",
    "\n",
    "# --- Preprocesamiento: Imputación de valores nulos ---\n",
    "numerical_cols = water_quality.drop('Potability', axis=1).columns\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "water_quality[numerical_cols] = imputer.fit_transform(water_quality[numerical_cols])\n",
    "\n",
    "# --- Crear la característica de ingeniería ph*Sulfate ---\n",
    "# Nos aseguramos de que las columnas existen antes de intentar multiplicarlas\n",
    "if 'ph' in water_quality.columns and 'Sulfate' in water_quality.columns:\n",
    "    water_quality['ph_sulfate_interaction'] = water_quality['ph'] * water_quality['Sulfate']\n",
    "    print(\"Característica 'ph_sulfate_interaction' creada.\")\n",
    "else:\n",
    "    print(\"Advertencia: 'ph' o 'Sulfate' no encontradas para crear la característica de interacción.\")\n",
    "\n",
    "\n",
    "# --- División en Características (X) y Variable Objetivo (y) ---\n",
    "X = water_quality.drop('Potability', axis=1)\n",
    "y = water_quality['Potability']\n",
    "\n",
    "# --- Escalado de Características ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled_with_fe = scaler.fit_transform(X) # Ahora con la característica de ingeniería\n",
    "\n",
    "# --- División en Conjuntos de Entrenamiento y Prueba ---\n",
    "# Usamos el nuevo X_scaled_with_fe\n",
    "X_train_fe, X_test_fe, y_train_fe, y_test_fe = train_test_split(X_scaled_with_fe, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nDimensiones del conjunto de entrenamiento X_train con FE: {X_train_fe.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba X_test con FE: {X_test_fe.shape}\")\n",
    "\n",
    "\n",
    "# --- Definición de la función evaluate_model ---\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Modelo\"):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de clasificación y muestra métricas clave.\n",
    "    Calcula Precision, Recall y F1-Score para la clase positiva (1).\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, pos_label=1, average='binary', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1, average='binary', zero_division=0)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"\\n--- Evaluación del {model_name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "    # Visualizar la matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['No Potable (0)', 'Potable (1)'],\n",
    "                yticklabels=['No Potable (0)', 'Potable (1)'])\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Real')\n",
    "    plt.title(f'Matriz de Confusión - {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualizar la curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_roc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "    plt.title(f'Curva ROC - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Re-entrenar LightGBM Optimizado con la nueva FE (usando los best_params_ encontrados en Hipótesis 4) ---\n",
    "# Primero, recuperamos los mejores parámetros de LightGBM de la Hipótesis 4\n",
    "# Nos aseguramos de que grid_search_lgbm.best_params_ esté disponible en el notebook\n",
    "# Copiar los parámetros directamente:\n",
    "best_lgbm_params = {'is_unbalance': True, 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 31}\n",
    "# Aquí los pasamos al constructor del modelo\n",
    "lgbm_fe_model = lgb.LGBMClassifier(**best_lgbm_params, objective='binary', random_state=42)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento que incluye la característica de ingeniería\n",
    "lgbm_fe_model.fit(X_train_fe, y_train_fe)\n",
    "\n",
    "print(\"Modelo LightGBM Optimizado entrenado con la característica de ingeniería 'ph_sulfate_interaction'.\")\n",
    "\n",
    "# Evaluar el modelo\n",
    "evaluate_model(lgbm_fe_model, X_test_fe, y_test_fe, model_name=\"LightGBM Optimizado + FE (Modelo_v7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab6664-556e-499c-b3b5-5fd7487b20d5",
   "metadata": {},
   "source": [
    "### Análisis de la Reintroducción de la Característica de Ingeniería:\n",
    "\n",
    "La reintroducción de la característica de ingeniería `ph_sulfate_interaction` con el LightGBM Optimizado **no resultó en una mejora sustancial** en el rendimiento general del modelo. Si bien se observó un ligero aumento en el Recall, esto vino acompañado de una disminución en la Precision, la Accuracy y el AUC-ROC, y el F1-Score se mantuvo prácticamente igual.\n",
    "\n",
    "Esto sugiere que, incluso para un modelo no lineal potente como LightGBM, la característica `ph_sulfate_interaction` no aporta una información discriminatoria adicional significativa que mejore el rendimiento más allá de lo ya logrado con las características originales.\n",
    "\n",
    "**Justificación de por qué esta es (o no es) la \"mejor\" versión del modelo hasta este punto:**\n",
    "\n",
    "El **LightGBM Optimizado + FE (Modelo_v7)** no supera claramente a las versiones anteriores de LightGBM (Modelo_v4 y Modelo_v5) en el balance general de métricas clave como F1-Score y AUC-ROC. En varias métricas, incluso muestra un rendimiento ligeramente inferior.\n",
    "\n",
    "Esto confirma la dificultad intrínseca del problema con los datos disponibles. Se ha probado:\n",
    "\n",
    "- Múltiples algoritmos (Regresión Logística, Random Forest, LightGBM).\n",
    "- Optimización de hiperparámetros.\n",
    "- Técnicas de manejo de desequilibrio de clases (`class_weight`, SMOTE).\n",
    "- Ingeniería de características (interacción `ph*Sulfate`).\n",
    "\n",
    "Y en cada paso, las mejoras han sido marginales o han implicado trade-offs que no mejoran el rendimiento general de manera decisiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a5e43-389a-4f0f-a4b8-f0d48f5f7a0f",
   "metadata": {},
   "source": [
    "## 9. Presentación del Modelo Final\n",
    "\n",
    "Después de un exhaustivo proceso iterativo de experimentación, evaluación y refinamiento, hemos identificado un modelo que representa el mejor compromiso de rendimiento para la clasificación de la potabilidad del agua en este dataset.\n",
    "\n",
    "### Identificación del Mejor Modelo\n",
    "\n",
    "Considerando el balance entre las métricas de rendimiento, especialmente la capacidad de detectar la clase minoritaria (Recall) y el equilibrio entre Precision y Recall (F1-Score) en un contexto de desequilibrio de clases, hemos seleccionado el **LightGBM Classifier optimizado con GridSearchCV (Modelo_v5)** como nuestro modelo final. Aunque el Random Forest optimizado (Modelo_v3) logró un AUC-ROC y una Accuracy ligeramente superiores, el LightGBM Optimizado ofrece un F1-Score notablemente mejorado, lo cual es crucial para la robustez en este tipo de problema.\n",
    "\n",
    "### Tipología del Modelo Final\n",
    "\n",
    "El modelo final es un algoritmo de **Gradient Boosting Machine (GBM)**, específicamente una implementación de **LightGBM**. Este es un modelo de ensemble basado en árboles de decisión que construye los árboles de forma secuencial, corrigiendo los errores de los árboles predecesores. LightGBM es conocido por su eficiencia y su alta capacidad predictiva.\n",
    "\n",
    "### Características Finales Utilizadas\n",
    "\n",
    "El modelo final utilizó las **9 características originales** del dataset de Calidad del Agua (`ph`, `Hardness`, `Solids`, `Chloramines`, `Sulfate`, `Carbonados`, `Conductivity`, `Organic_carbon`, `Trihalomethanes`), las cuales fueron previamente imputadas (valores nulos con la mediana) y escaladas (StandardScaler). La característica de ingeniería `ph_sulfate_interaction` no fue incluida en el modelo final, ya que en la Hipótesis 6 no mostró una mejora significativa en el rendimiento general del LightGBM.\n",
    "\n",
    "### Hiperparámetros Óptimos\n",
    "\n",
    "Los hiperparámetros óptimos encontrados por GridSearchCV para este modelo LightGBM son:\n",
    "\n",
    "- `is_unbalance`: `True`\n",
    "- `learning_rate`: `0.05`\n",
    "- `max_depth`: `-1` (sin límite de profundidad)\n",
    "- `min_child_samples`: `20`\n",
    "- `n_estimators`: `100`\n",
    "- `num_leaves`: `31`\n",
    "\n",
    "Para recordar el valor exacto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ded155-79a6-4be5-918d-b443b6307169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'best_lgbm_model' es el modelo final elegido\n",
    "print(\"Mejores parámetros finales del LightGBM:\", best_lgbm_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50fe75-b35d-4d85-842c-e720c0a6bd58",
   "metadata": {},
   "source": [
    "### Métricas y Resultados Finales en el Conjunto de Test\n",
    "\n",
    "Volvemos a presentar las métricas del LightGBM Optimizado (Modelo_v5) para su presentación concisa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02277256-7b9f-4f11-b2cd-357b7c614722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como no se tenía best_lgbm_model en memoria, se volvió a construir:\n",
    "best_lgbm_model = lgb.LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=-1, min_child_samples=20, n_estimators=100, num_leaves=31, objective='binary', random_state=42)\n",
    "best_lgbm_model.fit(X_train, y_train) # Asumiendo X_train, y_train sin FE ni SMOTE\n",
    "evaluate_model(best_lgbm_model, X_test, y_test, model_name=\"Modelo Final: LightGBM Optimizado (Modelo_v5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f75ad-debc-412a-be1f-976ac0b0c3dd",
   "metadata": {},
   "source": [
    "**Resultados del Modelo Final (LightGBM Optimizado - Modelo_v5):**\n",
    "\n",
    "- **Accuracy:** **0.6399**\n",
    "- **Precision:** **0.5428**\n",
    "- **Recall:** **0.4804**\n",
    "- **F1-Score:** **0.5097**\n",
    "- **AUC-ROC:** **0.6610**\n",
    "\n",
    "### Tiempo de Entrenamiento y Número de Iteraciones\n",
    "\n",
    "- **Tiempo de entrenamiento (aproximado):** El entrenamiento individual del modelo final (con los hiperparámetros óptimos) es muy rápido, en el orden de segundos (probablemente menos de 10 segundos). La fase de `GridSearchCV` para LightGBM toma más tiempo, pero para los parámetros elegidos y el tamaño del dataset, se mantuvo dentro del requisito de \"menos de 5 minutos por modelo/iteración de optimización\".\n",
    "- **Número de iteraciones:** El proceso iterativo incluyó:\n",
    "    1. Modelo Base (Regresión Logística).\n",
    "    2. Modelo Base con Ingeniería de Características.\n",
    "    3. Random Forest inicial.\n",
    "    4. Random Forest optimizado con GridSearchCV.\n",
    "    5. LightGBM base.\n",
    "    6. LightGBM optimizado con GridSearchCV (que internamente ejecuta múltiples iteraciones de CV).\n",
    "    7. LightGBM optimizado con SMOTE.\n",
    "    8. LightGBM optimizado con Característica de Ingeniería adicional.\n",
    "    Este proceso demuestra un enfoque exhaustivo y sistemático para la selección del mejor modelo.\n",
    "\n",
    "### Número de Ejemplos de Entrenamiento\n",
    "\n",
    "El modelo fue entrenado con aproximadamente **2293 ejemplos** (70% del dataset total de 3276 muestras) después del preprocesamiento y la división, sin la alteración del número de muestras por técnicas como SMOTE (para el modelo final elegido).\n",
    "\n",
    "### Análisis de Sesgo o Sobreajuste\n",
    "\n",
    "El modelo final exhibe un **equilibrio razonable entre sesgo y varianza**.\n",
    "\n",
    "- **Sesgo:** Dada la dificultad intrínseca del problema y el desequilibrio de clases, las métricas generales (Accuracy, AUC-ROC) son modestas, lo que podría sugerir que el modelo aún tiene cierto sesgo y no captura toda la complejidad de los datos. Sin embargo, hemos utilizado modelos no lineales potentes y técnicas de balanceo.\n",
    "- **Sobreajuste:** No hay señales claras de sobreajuste significativo. Las métricas en el conjunto de prueba son consistentes con lo que esperaríamos de un modelo bien generalizado después de la validación cruzada durante la optimización. La diferencia entre el rendimiento de entrenamiento y prueba (si se evaluara el entrenamiento) sería mínima o manejable.\n",
    "\n",
    "### Comparación Clara con el Modelo Base\n",
    "\n",
    "Para ilustrar la mejora, comparamos el rendimiento del modelo final (LightGBM Optimizado) con nuestro modelo base más simple (Regresión Logística Base con `class_weight='balanced'`):\n",
    "\n",
    "| Métrica | Regresión Logística (Base) | LightGBM Optimizado (Final) | Mejora (Aprox.) |\n",
    "| --- | --- | --- | --- |\n",
    "| Accuracy | 0.5229 | **0.6399** | ~11.7% |\n",
    "| Precision | 0.4154 | **0.5428** | ~12.7% |\n",
    "| Recall | **0.5509** | 0.4804 | -7.05% (reducción) |\n",
    "| F1-Score | 0.4736 | **0.5097** | ~3.6% |\n",
    "| AUC-ROC | 0.5295 | **0.6610** | ~13.15% |\n",
    "\n",
    "**Análisis de la Mejora:**\n",
    "La mejora es notable en la mayoría de las métricas clave, especialmente en Accuracy, Precision, F1-Score y AUC-ROC, lo que valida el enfoque iterativo y la elección de un modelo más complejo y su optimización. Aunque el Recall es ligeramente inferior al del modelo lineal base, el LightGBM ofrece un F1-Score superior, lo que indica un mejor equilibrio entre Precision y Recall. El incremento del AUC-ROC en más de 13 puntos porcentuales es una mejora sustancial en la capacidad discriminatoria del modelo.\n",
    "\n",
    "### Importancia de las Características\n",
    "\n",
    "Para los modelos basados en árboles como LightGBM, podemos inspeccionar la importancia de las características. Esto nos da una indicación de qué tan relevante fue cada característica para las decisiones de división en los árboles del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344e849-1ff2-4f84-b2f0-333dbb7d7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_quality_original = pd.read_csv(file_path)\n",
    "water_quality_original[numerical_cols] = imputer.fit_transform(water_quality_original[numerical_cols])\n",
    "X_original = water_quality_original.drop('Potability', axis=1) # Este X no tiene ph_sulfate_interaction\n",
    "feature_names = X_original.columns\n",
    "\n",
    "\n",
    "feature_importances = best_lgbm_model.feature_importances_\n",
    "features_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nImportancia de las Características en el Modelo Final (LightGBM):\")\n",
    "print(features_df)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=features_df)\n",
    "plt.title('Importancia de las Características (LightGBM Optimizado)')\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Característica')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba25a44-8880-427d-84c2-37061fd85ba2",
   "metadata": {},
   "source": [
    "**Observaciones sobre la Importancia de las Características:**\n",
    "Podemos observar qué características fueron más influyentes para el modelo final LightGBM. Típicamente, características como `Solids`, `Chloramines`, `Sulfate`, `Hardness` y `ph` suelen ser muy relevantes en datasets de calidad del agua, lo cual es coherente con su rol en la potabilidad. La importancia de las características nos ofrece una visión de qué propiedades del agua son más críticas para determinar su potabilidad según el modelo.\n",
    "\n",
    "### Justificación de su Idoneidad y Cumplimiento de los Requisitos Técnicos Iniciales\n",
    "\n",
    "El LightGBM Classifier optimizado es un modelo adecuado para este problema de clasificación por las siguientes razones:\n",
    "\n",
    "- **Rendimiento Equilibrado:** Supera claramente al modelo base y ofrece el mejor balance de métricas (F1-Score más alto, AUC-ROC muy competitivo), lo cual es crucial para un problema con desequilibrio de clases donde tanto la identificación correcta de positivos como la minimización de falsos positivos son importantes.\n",
    "- **Manejo de Desequilibrio de Clases:** Gracias al parámetro `is_unbalance=True`, el modelo es consciente del desequilibrio y busca un mejor rendimiento para la clase minoritaria, lo que se refleja en su Recall y F1-Score.\n",
    "- **Robustez y No Linealidad:** Como modelo basado en árboles, es robusto a los outliers y puede capturar relaciones no lineales complejas en los datos, a diferencia de un modelo lineal simple.\n",
    "- **Requisitos Técnicos:**\n",
    "    - **Métricas:** Todas las métricas clave (Accuracy, Precision, Recall, F1-Score, AUC-ROC) fueron calculadas y monitoreadas extensivamente durante todo el proceso.\n",
    "    - **Precisión mínima aceptable (>70-75%):** La `Accuracy` obtenida (0.6399) no cumple directamente este umbral. Sin embargo, el **`AUC-ROC` (0.6610)** sí muestra una capacidad discriminatoria aceptable, aunque **no alcanza el rango deseable (>0.85)** mencionado en el ejemplo del proyecto. Es importante reconocer que las métricas obtenidas con este dataset son más modestas que las de ejemplos quizás más simplificados o con más datos. El modelo sí demuestra ser mejor que una clasificación aleatoria.\n",
    "    - **Recursos y Tiempo de Entrenamiento:** El entrenamiento y la optimización se realizaron dentro de los límites de un entorno de Google Colab, jupyter Notebook o máquina estándar, y los tiempos de entrenamiento por iteración se mantuvieron dentro de los límites establecidos (menos de 5 minutos).\n",
    "\n",
    "**En conclusión**, este modelo representa un clasificador robusto y el mejor rendimiento alcanzable para el problema de la potabilidad del agua con el dataset y las características actuales, demostrando la efectividad de un enfoque iterativo y de prueba de hipótesis en Machine Learning. Si bien las métricas absolutas no alcanzan los valores muy altos que a veces se ven en ejemplos ideales, el proceso fue riguroso y los resultados son válidos dentro de las limitaciones del problema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
